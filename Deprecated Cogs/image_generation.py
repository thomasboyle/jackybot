import asyncio
import torch
from discord.ext import commands
import discord
from diffusers import StableDiffusionXLPipeline, DPMSolverMultistepScheduler
import io
from datetime import datetime, timedelta
import accelerate
import os

class ImageGenerationCog(commands.Cog):
    def __init__(self, bot):
        self.bot = bot
        self.pipe = None
        self.model_lock = asyncio.Lock()
        self.last_used = None
        self.cleanup_task = None
        
        # Default generation parameters (consider lowering resolution if acceptable)
        self.default_params = {
            "num_inference_steps": 12,
            "guidance_scale": 4,
            "height": 1024,
            "width": 1024
        }

    async def load_model(self):
        async with self.model_lock:
            if self.pipe is not None:
                return self.pipe
            
            loop = asyncio.get_running_loop()
            self.pipe = await loop.run_in_executor(None, self._load_model_sync)
            return self.pipe

    def _load_model_sync(self):
        # Load the model with half precision and low CPU memory usage.
        # Do not move the entire model to GPU immediately.
        pipe = StableDiffusionXLPipeline.from_single_file(
            "D:\\C++\\PythonPrograms\\JackyBot\\Safetensors\\juggernautXL_juggXIByRundiffusion.safetensors", 
            torch_dtype=torch.float16,
            low_cpu_mem_usage=True,
            token=os.environ.get("HF_TOKEN")
        )
        
        # Configure DPMSolver scheduler with Karras sigmas
        pipe.scheduler = DPMSolverMultistepScheduler.from_config(
            pipe.scheduler.config,
            use_karras_sigmas=True
        )
        
        # Enable attention slicing for lower memory usage
        pipe.enable_attention_slicing("max")
        pipe.enable_sequential_cpu_offload(device="cuda")
        
        return pipe

    def unload_model(self):
        if self.pipe is not None:
            del self.pipe
            self.pipe = None
            torch.cuda.empty_cache()

    def _get_generation_params(self, prompt):
        return {
            "prompt": prompt,
            **self.default_params  # Unpack default parameters
        }

    async def cleanup_check(self):
        # Periodically check if the model has been idle
        while True:
            await asyncio.sleep(30)  # Check every 30 seconds
            if self.last_used and self.pipe is not None:
                # Unload after 30 seconds of inactivity
                if datetime.now() - self.last_used > timedelta(seconds=30):
                    await asyncio.get_running_loop().run_in_executor(None, self.unload_model)
                    self.cleanup_task = None
                    return

    async def process_request(self, prompt, ctx):
        loop = asyncio.get_running_loop()
        try:
            pipe = await self.load_model()
            self.last_used = datetime.now()
            
            if not self.cleanup_task or self.cleanup_task.done():
                self.cleanup_task = asyncio.create_task(self.cleanup_check())
            
            async with ctx.typing():
                # Run generation synchronously in an executor
                image = await loop.run_in_executor(
                    None, lambda: pipe(**self._get_generation_params(prompt)).images[0]
                )
                
                with io.BytesIO() as img_byte_arr:
                    image.save(img_byte_arr, format='PNG', optimize=True, quality=90)
                    img_byte_arr.seek(0)
                    
                    file = discord.File(img_byte_arr, filename="SPOILER_output.png")
                    await ctx.reply(file=file)
                    
                    # Optionally, send the image to another channel for logging/archiving
                    if (other_channel := self.bot.get_channel(1133393726060888135)):
                        img_byte_arr.seek(0)
                        embed = discord.Embed(
                            title=f"Prompt: {prompt[:256]}",
                            description=f"Generated by: {ctx.author.name}\nServer: {ctx.guild.name if ctx.guild else 'Unknown Server'}", 
                            color=0x00ff00
                        )
                        embed.set_image(url="attachment://output.png")
                        await other_channel.send(
                            embed=embed, 
                            file=discord.File(img_byte_arr, filename="output.png")
                        )

            # Notice: We no longer unload the model immediately after each request.
            # The cleanup_check task will unload the model after 30 seconds of inactivity.

        except Exception as e:
            await ctx.reply(f"An error occurred: {str(e)}")
            # Optionally log the exception here

    def update_generation_params(self, **kwargs):
        """Update generation parameters temporarily or permanently"""
        self.default_params.update(kwargs)

async def setup(bot):
    await bot.add_cog(ImageGenerationCog(bot))
